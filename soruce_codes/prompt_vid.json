{
    "prompt": {
        "84": {
            "inputs": {
                "clip_name": "umt5_xxl_fp8_e4m3fn_scaled.safetensors",
                "type": "wan",
                "device": "default"
            },
            "class_type": "CLIPLoader",
            "_meta": {
                "title": "Load CLIP"
            }
        },
        "85": {
            "inputs": {
                "add_noise": "disable",
                "noise_seed": 0,
                "steps": 4,
                "cfg": 1,
                "sampler_name": "euler",
                "scheduler": "simple",
                "start_at_step": 2,
                "end_at_step": 4,
                "return_with_leftover_noise": "disable",
                "model": [
                    "103",
                    0
                ],
                "positive": [
                    "98",
                    0
                ],
                "negative": [
                    "98",
                    1
                ],
                "latent_image": [
                    "86",
                    0
                ]
            },
            "class_type": "KSamplerAdvanced",
            "_meta": {
                "title": "KSampler (Advanced)"
            }
        },
        "86": {
            "inputs": {
                "add_noise": "enable",
                "noise_seed": 138073435077572,
                "steps": 4,
                "cfg": 1,
                "sampler_name": "euler",
                "scheduler": "simple",
                "start_at_step": 0,
                "end_at_step": 2,
                "return_with_leftover_noise": "enable",
                "model": [
                    "104",
                    0
                ],
                "positive": [
                    "98",
                    0
                ],
                "negative": [
                    "98",
                    1
                ],
                "latent_image": [
                    "98",
                    2
                ]
            },
            "class_type": "KSamplerAdvanced",
            "_meta": {
                "title": "KSampler (Advanced)"
            }
        },
        "87": {
            "inputs": {
                "samples": [
                    "85",
                    0
                ],
                "vae": [
                    "90",
                    0
                ]
            },
            "class_type": "VAEDecode",
            "_meta": {
                "title": "VAE Decode"
            }
        },
        "89": {
            "inputs": {
                "text": null,
                "clip": [
                    "84",
                    0
                ]
            },
            "class_type": "CLIPTextEncode",
            "_meta": {
                "title": "CLIP Text Encode (Negative Prompt)"
            }
        },
        "90": {
            "inputs": {
                "vae_name": "wan_2.1_vae.safetensors"
            },
            "class_type": "VAELoader",
            "_meta": {
                "title": "Load VAE"
            }
        },
        "93": {
            "inputs": {
                "text": "a sexy woman dancing attractively with smiling face",
                "clip": [
                    "84",
                    0
                ]
            },
            "class_type": "CLIPTextEncode",
            "_meta": {
                "title": "CLIP Text Encode (Positive Prompt)"
            }
        },
        "94": {
            "inputs": {
                "fps": 24,
                "images": [
                    "87",
                    0
                ]
            },
            "class_type": "CreateVideo",
            "_meta": {
                "title": "Create Video"
            }
        },
        "95": {
            "inputs": {
                "unet_name": "wan2.2_i2v_high_noise_14B_fp8_scaled.safetensors",
                "weight_dtype": "default"
            },
            "class_type": "UNETLoader",
            "_meta": {
                "title": "Load Diffusion Model"
            }
        },
        "96": {
            "inputs": {
                "unet_name": "wan2.2_i2v_low_noise_14B_fp8_scaled.safetensors",
                "weight_dtype": "default"
            },
            "class_type": "UNETLoader",
            "_meta": {
                "title": "Load Diffusion Model"
            }
        },
        "97": {
            "inputs": {
                "image": "woman0.png"
            },
            "class_type": "LoadImage",
            "_meta": {
                "title": "Load Image"
            }
        },
        "98": {
            "inputs": {
                "width": 720,
                "height": 1088,
                "length": 120,
                "batch_size": 1,
                "positive": [
                    "93",
                    0
                ],
                "negative": [
                    "89",
                    0
                ],
                "vae": [
                    "90",
                    0
                ],
                "start_image": [
                    "97",
                    0
                ]
            },
            "class_type": "WanImageToVideo",
            "_meta": {
                "title": "WanImageToVideo"
            }
        },
        "101": {
            "inputs": {
                "lora_name": "wan2.2_i2v_lightx2v_4steps_lora_v1_high_noise.safetensors",
                "strength_model": 1.0000000000000002,
                "model": [
                    "95",
                    0
                ]
            },
            "class_type": "LoraLoaderModelOnly",
            "_meta": {
                "title": "LoraLoaderModelOnly"
            }
        },
        "102": {
            "inputs": {
                "lora_name": "wan2.2_i2v_lightx2v_4steps_lora_v1_low_noise.safetensors",
                "strength_model": 1.0000000000000002,
                "model": [
                    "96",
                    0
                ]
            },
            "class_type": "LoraLoaderModelOnly",
            "_meta": {
                "title": "LoraLoaderModelOnly"
            }
        },
        "103": {
            "inputs": {
                "shift": 5.000000000000001,
                "model": [
                    "102",
                    0
                ]
            },
            "class_type": "ModelSamplingSD3",
            "_meta": {
                "title": "ModelSamplingSD3"
            }
        },
        "104": {
            "inputs": {
                "shift": 5.000000000000001,
                "model": [
                    "101",
                    0
                ]
            },
            "class_type": "ModelSamplingSD3",
            "_meta": {
                "title": "ModelSamplingSD3"
            }
        },
        "108": {
            "inputs": {
                "filename_prefix": "woman0",
                "format": "mp4",
                "codec": "auto",
                "video": [
                    "94",
                    0
                ]
            },
            "class_type": "SaveVideo",
            "_meta": {
                "title": "Save Video"
            }
        }
    }
}