"""Vast.ai helper ëª¨ë“ˆ: GPU ì˜¤í¼ ê²€ìƒ‰ ë° ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬."""

import os
import warnings
from typing import Any, Dict, List, Optional, Union

from vastai_sdk import VastAI

# ìƒìˆ˜
POLL_INTERVAL_SECONDS = 5
MB_TO_GB_RATIO = 1024
DEFAULT_OFFER_LIMIT = 200

class VastInstance:
    """Vast.ai ì¸ìŠ¤í„´ìŠ¤ë¥¼ í‘œí˜„í•˜ëŠ” í´ë˜ìŠ¤.
    
    Attributes:
        id: ì¸ìŠ¤í„´ìŠ¤ ID
        status: ì¸ìŠ¤í„´ìŠ¤ ìƒíƒœ ë¬¸ìì—´ (ì†Œë¬¸ì)
        gpu_name: GPU ëª¨ë¸ëª…
        gpu_ram: GPU VRAM ìš©ëŸ‰ (MB)
        gpu_frac: GPU í• ë‹¹ ë¹„ìœ¨ (0.0-1.0)
        dph_total: ì‹œê°„ë‹¹ ì´ ë¹„ìš© ($/h)
        dlperf_per_dph: ë”¥ëŸ¬ë‹ ì„±ëŠ¥ ëŒ€ë¹„ ë¹„ìš© íš¨ìœ¨ì„±
        cur_state: í˜„ì¬ ì‹¤í–‰ ìƒíƒœ
        intended_status: ì˜ë„ëœ ìƒíƒœ
        ssh_host: SSH ì ‘ì† í˜¸ìŠ¤íŠ¸
        ssh_port: SSH í¬íŠ¸ ë²ˆí˜¸  
        public_ipaddr: ê³µê°œ IP ì£¼ì†Œ
        reliability: ì‹ ë¢°ë„ ì§€ìˆ˜
        geolocation: ì§€ë¦¬ì  ìœ„ì¹˜
        ports: í¬íŠ¸ ì„¤ì • ì •ë³´
        ssh: SSH ì„¤ì • ì •ë³´
    """
    
    def __init__(self, data: Dict[str, Any]) -> None:
        """Vast.ai API ì‘ë‹µ ë°ì´í„°ë¡œë¶€í„° ì¸ìŠ¤í„´ìŠ¤ ê°ì²´ ìƒì„±."""
        # ìƒíƒœ ì •ë³´ (ìš°ì„ ìˆœìœ„: actual_status > status_msg > status)
        self.status: str = (
            data.get("actual_status") or 
            data.get("status_msg") or 
            data.get("status") or 
            ""
        ).lower()
        
        # ê¸°ë³¸ ì •ë³´
        self.id: Optional[int] = data.get("id")
        self.gpu_name: Optional[str] = data.get("gpu_name")
        self.gpu_ram: Optional[int] = data.get("gpu_ram")  # MB
        self.gpu_frac: Optional[float] = data.get("gpu_frac")
        self.dph_total: Optional[float] = data.get("dph_total")
        self.dlperf_per_dph: Optional[float] = data.get("dlperf_per_dph")
        
        # ì‹¤í–‰ ìƒíƒœ
        self.cur_state: Optional[str] = data.get("cur_state")
        self.intended_status: Optional[str] = data.get("intended_status")
        
        # ë„¤íŠ¸ì›Œí¬ ì •ë³´
        self.ssh_host: Optional[str] = data.get("ssh_host")
        self.ssh_port: Optional[int] = data.get("ssh_port")
        self.public_ipaddr: Optional[str] = data.get("public_ipaddr")
        
        # ë©”íƒ€ë°ì´í„°
        self.reliability: Optional[float] = data.get("reliability2")
        self.geolocation: Optional[str] = data.get("geolocation")
        self.ports: Optional[Any] = data.get("ports")
        self.ssh: Optional[Any] = data.get("ssh")
    
    def __str__(self) -> str:
        """ì¸ìŠ¤í„´ìŠ¤ ì •ë³´ë¥¼ ë¬¸ìì—´ë¡œ ë°˜í™˜."""
        return (
            f"VastInstance("
            f"id={self.id}, "
            f"gpu_name={self.gpu_name}, "
            f"gpu_ram={self.gpu_ram}, "
            f"gpu_frac={self.gpu_frac}, "
            f"dph_total={self.dph_total}, "
            f"cur_state={self.cur_state}, "
            f"ssh_host={self.ssh_host}, "
            f"ssh_port={self.ssh_port}, "
            f"geolocation={self.geolocation}"
            f")"
        )
    
    def __repr__(self) -> str:
        """ê°œë°œììš© ë¬¸ìì—´ í‘œí˜„."""
        return self.__str__()

class VastHelper:
    """Vast.ai í—¬í¼: ë‚´ë¶€ì ìœ¼ë¡œ VastAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ê´€ë¦¬í•˜ê³ , ì˜¤í¼ ê²€ìƒ‰/ë­í‚¹ ì œê³µ."""

    def __init__(self, api_key: Optional[str] = None) -> None:
        """VastHelper ì´ˆê¸°í™”.
        
        Args:
            api_key: Vast.ai API í‚¤. Noneì´ë©´ VAST_API_KEY í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©
        """
        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ í‚¤ë¥¼ ì½ë˜, ì´ ë‹¨ê³„ì—ì„œëŠ” .env ë¡œë”©ì„ ìˆ˜í–‰í•˜ì§€ ì•ŠìŒ
        self.api_key: Optional[str] = api_key or os.getenv("VAST_API_KEY")
        self.client: Optional[VastAI] = None
        
        if not self.api_key:
            warnings.warn(
                "VAST_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. VastHelperëŠ” API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.",
                UserWarning,
                stacklevel=2
            )
            return
            
        try:
            self.client = VastAI(api_key=self.api_key)
        except Exception as exc:
            warnings.warn(
                f"VastAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {exc}",
                RuntimeWarning,
                stacklevel=2
            )
            self.client = None

    def check_client(self, print_output: bool = False) -> bool:
        """í´ë¼ì´ì–¸íŠ¸ê°€ ì •ìƒì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆëŠ”ì§€ í™•ì¸
        
        Args:
            print_output (bool): ì—ëŸ¬ ë°œìƒ ì‹œ ì¶œë ¥í• ì§€ ì—¬ë¶€
            
        Returns:
            bool: í´ë¼ì´ì–¸íŠ¸ê°€ ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ True, ì•„ë‹ˆë©´ False
        """
        if self.client is None:
            if print_output:
                if not self.api_key:
                    print("âŒ VastHelper ì´ˆê¸°í™” ì‹¤íŒ¨: VAST_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                else:
                    print("âŒ VastHelper ì´ˆê¸°í™” ì‹¤íŒ¨: VastAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return False
        return True

    @staticmethod
    def calculate_metrics(offer: Dict[str, Any]) -> Dict[str, Any]:
        """ì˜¤í¼ì˜ ê°€ì„±ë¹„ ì§€í‘œë“¤ì„ ê³„ì‚°.
        
        Args:
            offer: Vast.ai ì˜¤í¼ ë°ì´í„°
            
        Returns:
            ê°€ì„±ë¹„ ì§€í‘œê°€ í¬í•¨ëœ ë”•ì…”ë„ˆë¦¬
        """
        dph = offer.get("dph_total", float("inf"))
        vram_gb = offer.get("gpu_ram", 0) / MB_TO_GB_RATIO  # MB to GB
        dlperf_per_dph = offer.get("dlperf_per_dphtotal", 0.0)
        reliability = offer.get("reliability", 0.0)
        gpu_frac = offer.get("gpu_frac", 1.0)

        cost_per_vram_gb = dph / vram_gb if vram_gb > 0 else float("inf")

        return {
            'offer': offer,
            'dph_total': dph,
            'vram_gb': vram_gb,
            'dlperf_per_dph': dlperf_per_dph,
            'reliability': reliability,
            'cost_per_vram_gb': cost_per_vram_gb,
            'gpu_frac': gpu_frac
        }

    @staticmethod
    def comprehensive_score(
        metrics: Dict[str, Any],
        weight_dlperf: float = 0.6,
        weight_reliability: float = 0.2,
        weight_gpu_frac: float = 0.2,
        reliability_scale: float = 20.0,
        gpu_frac_scale: float = 20.0,
    ) -> float:
        """ì¢…í•© ì ìˆ˜ ê³„ì‚° (ë”¥ëŸ¬ë‹ ì„±ëŠ¥, ì‹ ë¢°ë„, GPU ì „ìš©ë„ ê³ ë ¤).
        
        Args:
            metrics: calculate_metricsë¡œ ê³„ì‚°ëœ ì§€í‘œ ë”•ì…”ë„ˆë¦¬
            weight_dlperf: dlperf_per_dphtotal ê°€ì¤‘ì¹˜
            weight_reliability: reliability ê°€ì¤‘ì¹˜  
            weight_gpu_frac: gpu_frac ê°€ì¤‘ì¹˜
            reliability_scale: reliability ìŠ¤ì¼€ì¼ë§ ê³„ìˆ˜
            gpu_frac_scale: gpu_frac ìŠ¤ì¼€ì¼ë§ ê³„ìˆ˜
            
        Returns:
            ì¢…í•© ì ìˆ˜ (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
        """
        dlperf_term = metrics['dlperf_per_dph'] * weight_dlperf
        reliability_term = metrics['reliability'] * reliability_scale * weight_reliability
        gpu_frac_term = metrics['gpu_frac'] * gpu_frac_scale * weight_gpu_frac
        return dlperf_term + reliability_term + gpu_frac_term

    def find_best_offer(
        self,
        *,
        print_output: bool = False,
        gpu_model: str = "A100",
        min_vram_mb: int = 0,
        min_gpu_frac: float = 0.0,
        weight_dlperf: float = 0.6,
        weight_reliability: float = 0.2,
        weight_gpu_frac: float = 0.2,
        reliability_scale: float = 20.0,
        gpu_frac_scale: float = 20.0,
    ) -> Optional[Dict[str, Any]]:
        """ì§€ì •ëœ GPU ëª¨ë¸ ì¤‘ì—ì„œ ìµœê³  ê°€ì„±ë¹„ ì˜¤í¼ ì°¾ê¸°
        
        Args:
            print_output (bool): Trueë©´ ë¶„ì„ ê³¼ì • ì¶œë ¥, Falseë©´ ê²°ê³¼ë§Œ ë°˜í™˜
            gpu_model (str): ê²€ìƒ‰í•  GPU ëª¨ë¸ëª… (ì˜ˆ: "A100", "H100", "RTX4090")
            min_vram_mb (int): ìµœì†Œ VRAM ìš©ëŸ‰ (MB ë‹¨ìœ„, 40960 = 40GB)
            min_gpu_frac (float): ì´ ê°’ ì´ìƒ(gpu_frac >= min_gpu_frac)ì¸ ì˜¤í¼ë§Œ ì„ íƒ
            weight_dlperf (float): dlperf_per_dphtotal ê°€ì¤‘ì¹˜
            weight_reliability (float): reliability ê°€ì¤‘ì¹˜
            weight_gpu_frac (float): gpu_frac ê°€ì¤‘ì¹˜
            reliability_scale (float): reliability ìŠ¤ì¼€ì¼ë§ ê³„ìˆ˜
            gpu_frac_scale (float): gpu_frac ìŠ¤ì¼€ì¼ë§ ê³„ìˆ˜
        """

        if not self.check_client(print_output=print_output):
            return None

        try:
            offers = self.client.search_offers(
                query=f"gpu_name~{gpu_model} rentable=true rented=false verified=true",
                limit=DEFAULT_OFFER_LIMIT,
            )
        except Exception as exc:
            if print_output:
                print(f"âŒ ì˜¤í¼ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {exc}")
            return None

        # í•„í„°ë§ ì¡°ê±´ì— ë§ëŠ” ì˜¤í¼ë§Œ ì„ íƒ
        filtered_offers = [
            offer for offer in offers
            if (
                "gpu_name" in offer
                and gpu_model.lower() in offer["gpu_name"].lower()
                and offer.get("gpu_ram", 0) >= min_vram_mb
                and offer.get("gpu_frac", 1.0) >= min_gpu_frac
            )
        ]

        if not filtered_offers:
            if print_output:
                print(f"âŒ ì¡°ê±´ì— ë§ëŠ” {gpu_model} GPU ì˜¤í¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None

        metrics = [self.calculate_metrics(offer) for offer in filtered_offers]

        best_dl_perf = sorted(metrics, key=lambda x: (-x['dlperf_per_dph'], x['dph_total']))
        best_cost_per_vram = sorted(metrics, key=lambda x: x['cost_per_vram_gb'])
        best_price = sorted(metrics, key=lambda x: x['dph_total'])

        if print_output:
            vram_gb = min_vram_mb / MB_TO_GB_RATIO
            vram_str = f"{vram_gb:.0f}GB+" if min_vram_mb > 0 else "ëª¨ë“  ìš©ëŸ‰"
            print(f"ğŸš€ {gpu_model} {vram_str} GPU ì¶”ì²œ ìˆœìœ„\n" + "="*80)

            print("\nğŸ“Š 1. ë”¥ëŸ¬ë‹ ê°€ì„±ë¹„ TOP 5 (ì„±ëŠ¥/ê°€ê²© ê¸°ì¤€)")
            print(f"{'ID':<8} {'GPU':<16} {'VRAM':<7} {'Price':<8} {'DLì„±ëŠ¥/ê°€ê²©':<12} {'ì‹ ë¢°ë„':<6} {'GPUë¹„ìœ¨':<8}")
            print("-" * 75)
            for i, m in enumerate(best_dl_perf[:5], 1):
                o = m['offer']
                print(f"{o.get('id',''):<8} {o.get('gpu_name',''):<16} {m['vram_gb']:<7.1f} ${m['dph_total']:<7.3f} {m['dlperf_per_dph']:<12.2f} {m['reliability']:<6.2f} {m['gpu_frac']:<8.2f}")

            print(f"\nğŸ’° 2. VRAM ê°€ì„±ë¹„ TOP 5 ($/GB ê¸°ì¤€)")
            print(f"{'ID':<8} {'GPU':<16} {'VRAM':<7} {'Price':<8} {'$/GBÂ·h':<8} {'ì‹ ë¢°ë„':<6} {'GPUë¹„ìœ¨':<8}")
            print("-" * 70)
            for i, m in enumerate(best_cost_per_vram[:5], 1):
                o = m['offer']
                print(f"{o.get('id',''):<8} {o.get('gpu_name',''):<16} {m['vram_gb']:<7.1f} ${m['dph_total']:<7.3f} {m['cost_per_vram_gb']:<7.4f} {m['reliability']:<6.2f} {m['gpu_frac']:<8.2f}")

            print(f"\nğŸ’¸ 3. ìµœì €ê°€ TOP 5")
            print(f"{'ID':<8} {'GPU':<16} {'VRAM':<7} {'Price':<8} {'DLì„±ëŠ¥/ê°€ê²©':<12} {'ì‹ ë¢°ë„':<6}")
            print("-" * 68)
            for i, m in enumerate(best_price[:5], 1):
                o = m['offer']
                print(f"{o.get('id',''):<8} {o.get('gpu_name',''):<16} {m['vram_gb']:<7.1f} ${m['dph_total']:<7.3f} {m['dlperf_per_dph']:<12.2f} {m['reliability']:<6.2f}")

        best_overall = sorted(
            metrics,
            key=lambda m: self.comprehensive_score(
                metrics=m,
                weight_dlperf=weight_dlperf,
                weight_reliability=weight_reliability,
                weight_gpu_frac=weight_gpu_frac,
                reliability_scale=reliability_scale,
                gpu_frac_scale=gpu_frac_scale,
            ),
            reverse=True,
        )

        if print_output:
            print(f"\nâ­ ìµœì¢… ì¶”ì²œ GPU")
            print("="*50)

        if best_overall:
            top = best_overall[0]
            o = top['offer']

            if print_output:
                print(f"ID: {o.get('id', '')}")
                print(f"GPU: {o.get('gpu_name', '')}")
                print(f"VRAM: {top['vram_gb']:.1f}GB")
                print(f"ê°€ê²©: ${top['dph_total']:.3f}/ì‹œê°„")
                print(f"DL ì„±ëŠ¥/ê°€ê²©: {top['dlperf_per_dph']:.2f}")
                print(f"ì‹ ë¢°ë„: {top['reliability']:.2f}")
                print(f"GPU ì „ìš©ë„: {top['gpu_frac']:.2f}")
                print(f"VRAM ë‹¹ ë¹„ìš©: ${top['cost_per_vram_gb']:.4f}/GBÂ·h")
                print(f"ìœ„ì¹˜: {o.get('geolocation', 'N/A')}")

            return top
        else:
            if print_output:
                print("ì¡°ê±´ì— ë§ëŠ” GPUë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None

    def get_instances(self) -> Optional[List[VastInstance]]:
        """ì‚¬ìš©ìì˜ ëª¨ë“  ì¸ìŠ¤í„´ìŠ¤ ëª©ë¡ ì¡°íšŒ.
        
        Returns:
            VastInstance ê°ì²´ë“¤ì˜ ë¦¬ìŠ¤íŠ¸. ì‹¤íŒ¨ ì‹œ None
        """
        if not self.check_client():
            return None
            
        try:
            instances_data = self.client.show_instances()
            return [VastInstance(instance_data) for instance_data in instances_data]
        except Exception as exc:
            warnings.warn(
                f"ì¸ìŠ¤í„´ìŠ¤ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {exc}",
                RuntimeWarning,
                stacklevel=2
            )
            return None


# í•˜ìœ„ í˜¸í™˜: ê¸°ì¡´ í•¨ìˆ˜í˜• API ìœ ì§€ (ë‚´ë¶€ì ìœ¼ë¡œ í´ë˜ìŠ¤ ì‚¬ìš©)
def find_best_gpu(*args: Any, **kwargs: Any) -> Optional[Dict[str, Any]]:
    """í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ í•¨ìˆ˜í˜• API.
    
    ë‚´ë¶€ì ìœ¼ë¡œ VastHelper í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    ìƒˆ ì½”ë“œì—ì„œëŠ” VastHelper í´ë˜ìŠ¤ë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.
    """
    helper = VastHelper()
    return helper.find_best_offer(*args, **kwargs)


if __name__ == "__main__":
    # ì˜ˆì œ ì‹¤í–‰: RTX 4090 GPU ê²€ìƒ‰ (GPU ì ˆë°˜ ê³µìœ ê¹Œì§€ í—ˆìš©)
    from dotenv import load_dotenv
    load_dotenv()
    
    helper = VastHelper()
    result = helper.find_best_offer(
        print_output=True,
        gpu_model="A100",
        min_vram_mb=40960,  # 40GB+
        min_gpu_frac=0.5
    )